{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mutual_info_classif' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-72026f8b9a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSelectKBest\u001b[0m \u001b[1;31m#特征选择\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mchi2\u001b[0m \u001b[1;31m#卡方统计量\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmutual_info_classif\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m  \u001b[1;31m#数据归一化\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m \u001b[1;31m#主成分分析\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mutual_info_classif' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn import tree #决策树\n",
    "from sklearn.tree import DecisionTreeClassifier #分类树\n",
    "from sklearn.model_selection  import train_test_split#测试集和训练集\n",
    "from sklearn.pipeline import Pipeline #管道\n",
    "from sklearn.feature_selection import SelectKBest #特征选择\n",
    "from sklearn.feature_selection import chi2 #卡方统计量\n",
    "mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler  #数据归一化\n",
    "from sklearn.decomposition import PCA #主成分分析\n",
    "from sklearn.model_selection import GridSearchCV #网格搜索交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 设置属性防止中文乱码\n",
    "mpl.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_feature_E = 'sepal length', 'sepal width', 'petal length', 'petal width'\n",
    "iris_feature_C = '花萼长度', '花萼宽度', '花瓣长度', '花瓣宽度'\n",
    "iris_class = 'Iris-setosa', 'Iris-versicolor', 'Iris-virginica'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#读取数据\n",
    "path = './datas/iris.data'  \n",
    "data = pd.read_csv(path, header=None)\n",
    "x=data[list(range(4))]#获取X变量\n",
    "y=pd.Categorical(data[4]).codes#把Y转换成分类型的0,1,2\n",
    "print(\"总样本数目：%d;特征属性数目:%d\" % x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#数据进行分割（训练数据和测试数据）\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x, y, train_size=0.8, random_state=14)\n",
    "x_train, x_test, y_train, y_test = x_train1, x_test1, y_train1, y_test1\n",
    "print (\"训练数据集样本数目：%d, 测试数据集样本数目：%d\" % (x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数据标准化\n",
    "#StandardScaler (基于特征矩阵的列，将属性值转换至服从正态分布)\n",
    "#标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，将样本的特征值转换到同一量纲下\n",
    "#常用与基于正态分布的算法，比如回归\n",
    "#数据归一化\n",
    "#MinMaxScaler （区间缩放，基于最大最小值，讲数据转换到0,1区间上的）\n",
    "#提升模型收敛速度，提升模型精度\n",
    "#常见用于神经网络\n",
    "#Normalizer （基于矩阵的行，将样本向量转换为单位向量）\n",
    "#其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准\n",
    "#常见用于文本分类和聚类、logistic回归中也会使用，有效防止过拟合\n",
    "ss = MinMaxScaler ()\n",
    "#用标准化方法对数据进行处理并转换\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)\n",
    "print (\"原始数据各个特征属性的调整最小值:\",ss.min_)\n",
    "print (\"原始数据各个特征属性的缩放数据值:\",ss.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#特征选择：从已有的特征中选择出影响目标值最大的特征属性\n",
    "#常用方法：{ 分类：F统计量、卡方系数，互信息mutual_info_classif\n",
    "        #{ 连续：皮尔逊相关系数 F统计量 互信息mutual_info_classif\n",
    "#SelectKBest（卡方系数）\n",
    "\n",
    "ch2 = SelectKBest(chi2,k=3)#在当前的案例中，使用SelectKBest这个方法从4个原始的特征属性，选择出来3个\n",
    "#K默认为10\n",
    "#如果指定了，那么就会返回你所想要的特征的个数\n",
    "x_train = ch2.fit_transform(x_train, y_train)#训练并转换\n",
    "x_test = ch2.transform(x_test)#转换\n",
    "\n",
    "select_name_index = ch2.get_support(indices=True)\n",
    "print (\"对类别判断影响最大的三个特征属性分布是:\",ch2.get_support(indices=False))\n",
    "print(select_name_index)\n",
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#降维：对于数据而言，如果特征属性比较多，在构建过程中，会比较复杂，这个时候考虑将多维（高维）映射到低维的数据\n",
    "#常用的方法：\n",
    "#PCA：主成分分析（无监督）\n",
    "#LDA：线性判别分析（有监督）类内方差最小，人脸识别，通常先做一次pca\n",
    "\n",
    "pca = PCA(n_components=2)#构建一个pca对象，设置最终维度是2维\n",
    "#这里是为了后面画图方便，所以将数据维度设置了2维，一般用默认不设置参数就可以\n",
    "\n",
    "x_train = pca.fit_transform(x_train)#训练并转换\n",
    "x_test = pca.transform(x_test)#转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#模型的构建\n",
    "model = DecisionTreeClassifier(criterion='entropy',random_state=0)#另外也可选gini \n",
    "#模型训练\n",
    "model.fit(x_train, y_train)\n",
    "#模型预测\n",
    "y_test_hat = model.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#模型结果的评估\n",
    "y_test2 = y_test.reshape(-1)\n",
    "result = (y_test2 == y_test_hat)\n",
    "print (\"准确率:%.2f%%\" % (np.mean(result) * 100))\n",
    "#实际可通过参数获取\n",
    "print (\"Score：\", model.score(x_test, y_test))#准确率\n",
    "print (\"Classes:\", model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#画图\n",
    "N = 100  #横纵各采样多少个值\n",
    "x1_min = np.min((x_train.T[0].min(), x_test.T[0].min()))\n",
    "x1_max = np.max((x_train.T[0].max(), x_test.T[0].max()))\n",
    "x2_min = np.min((x_train.T[1].min(), x_test.T[1].min()))\n",
    "x2_max = np.max((x_train.T[1].max(), x_test.T[1].max()))\n",
    "\n",
    "t1 = np.linspace(x1_min, x1_max, N)\n",
    "t2 = np.linspace(x2_min, x2_max, N)\n",
    "x1, x2 = np.meshgrid(t1, t2)  # 生成网格采样点\n",
    "x_show = np.dstack((x1.flat, x2.flat))[0] #测试点\n",
    "\n",
    "y_show_hat = model.predict(x_show) #预测值\n",
    "\n",
    "y_show_hat = y_show_hat.reshape(x1.shape)  #使之与输入的形状相同\n",
    "print(y_show_hat.shape)\n",
    "y_show_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#画图\n",
    "plt_light = mpl.colors.ListedColormap(['#A0FFA0', '#FFA0A0', '#A0A0FF'])\n",
    "plt_dark = mpl.colors.ListedColormap(['g', 'r', 'b'])\n",
    "\n",
    "plt.figure(facecolor='w')\n",
    "plt.pcolormesh(x1, x2, y_show_hat, cmap=plt_light) \n",
    "plt.scatter(x_test.T[0], x_test.T[1], c=y_test.ravel(), edgecolors='k', s=150, zorder=10, cmap=plt_dark, marker='*')  # 测试数据\n",
    "plt.scatter(x_train.T[0], x_train.T[1], c=y_train.ravel(), edgecolors='k', s=40, cmap=plt_dark)  # 全部数据\n",
    "plt.xlabel(u'特征属性1', fontsize=15)\n",
    "plt.ylabel(u'特征属性2', fontsize=15)\n",
    "plt.xlim(x1_min, x1_max)\n",
    "plt.ylim(x2_min, x2_max)\n",
    "plt.grid(True)\n",
    "plt.title(u'鸢尾花数据的决策树分类', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#参数优化\n",
    "pipe = Pipeline([\n",
    "            ('mms', MinMaxScaler()),\n",
    "            ('skb', SelectKBest(chi2,k=3)),\n",
    "            ('pca', PCA()),\n",
    "            ('decision', DecisionTreeClassifier())\n",
    "        ])\n",
    "\n",
    "# 参数\n",
    "parameters = {\n",
    "    \"skb__k\": [1,2,3,4],\n",
    "    \"pca__n_components\": [0.5,0.99],#设置为浮点数代表主成分方差所占最小比例的阈值，这里不建议设置为数值，思考一下？\n",
    "    \"decision__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"decision__max_depth\": [1,2,3,4,5,6,7,8,9,10]\n",
    "}\n",
    "#数据\n",
    "x_train2, x_test2, y_train2, y_test2 = x_train1, x_test1, y_train1, y_test1\n",
    "#模型构建\n",
    "gscv = GridSearchCV(pipe, param_grid=parameters,cv=3)\n",
    "#模型训练\n",
    "gscv.fit(x_train2, y_train2)\n",
    "#算法的最优解\n",
    "print(\"最优参数列表:\", gscv.best_params_)\n",
    "print(\"score值：\",gscv.best_score_)\n",
    "#预测值\n",
    "y_test_hat2 = gscv.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#应用最优参数看效果\n",
    "mms_best = MinMaxScaler()\n",
    "skb_best = SelectKBest(chi2, k=3)\n",
    "pca_best = PCA(n_components=0.99)\n",
    "decision3 = DecisionTreeClassifier(criterion='gini', max_depth=7)\n",
    "#构建模型并训练模型\n",
    "x_train3, x_test3, y_train3, y_test3 = x_train1, x_test1, y_train1, y_test1\n",
    "x_train3 = pca_best.fit_transform(skb_best.fit_transform(mms_best.fit_transform(x_train3), y_train3))\n",
    "x_test3 = pca_best.transform(skb_best.transform(mms_best.transform(x_test3)))\n",
    "decision3.fit(x_train3, y_train3)\n",
    "\n",
    "print(\"正确率:\", decision3.score(x_test3, y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#基于原始数据前3列比较一下决策树在不同深度的情况下错误率\n",
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(x.iloc[:, :2], y, train_size=0.7, random_state=14)\n",
    "\n",
    "depths = np.arange(1, 15)\n",
    "err_list = []\n",
    "for d in depths:\n",
    "    clf = DecisionTreeClassifier(criterion='gini', max_depth=d)#仅设置了这二个参数，没有对数据进行特征选择和降维，所以跟前面得到的结果不同\n",
    "    clf.fit(x_train4, y_train4)\n",
    "    \n",
    "    score = clf.score(x_test4, y_test4)\n",
    "    err = 1 - score\n",
    "    err_list.append(err)\n",
    "    print(\"%d深度，正确率%.5f\" % (d, score))\n",
    "\n",
    "## 画图\n",
    "plt.figure(facecolor='w')\n",
    "plt.plot(depths, err_list, 'ro-', lw=3)\n",
    "plt.xlabel(u'决策树深度', fontsize=16)\n",
    "plt.ylabel(u'错误率', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.title(u'决策树层次太多导致的拟合问题(欠拟合和过拟合)', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
